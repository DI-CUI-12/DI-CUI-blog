{
  "hash": "a6c1aefe2a606c7fe2385dc748a31be5",
  "result": {
    "markdown": "---\ntitle: \"Handwriting Analysis\"\nexecute: \n  echo: false\n  warning: false\n  message: false\n  error: false\nauthor: \"Di Cui\"\ndate: \"2023-05-15\"\ncategories: [Machine Learning]\nimage: \"machine_learning.png\"\nformat: \n  html:\n    toc: true\n    code-fold: true\n    css: machine_learning.css\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Introduction\n\nThe analysis of handwriting has always held a captivating allure, offering insights into the distinctive subtleties of human expression. Even in today's digital age, the study of handwriting remains relevant, finding applications in fields like forensic document examination, linguistics, and personalized marketing. This report delves into the realm of handwritten letter classification by employing a combination of Principal Component Analysis (PCA) and machine learning methodologies. By harnessing these techniques, our aim is to unravel the unique variations in individuals' letter-writing styles, ultimately contributing to a deeper comprehension of the intricate art of handwriting.\n\n\n## Data Description\n\nThe data is based on the EMNIST dataset that contains a 28x28 pixel image of a letter from the 26-letter Roman alphabet. You can find details about this [dataset](https://arxiv.org/pdf/1702.05373v1.pdf) in this article.\n\nMy dataset is assigned a single random letter and a random subset from this dataset. Separate to this main data, the dataset will also have a new records dataset that contains five observations. \n\nEach row of the data is an image. Each column corresponds to one pixel value. There are 28 x 28 = 784 columns in total. The image is a single letter with a mix of upper case and lower case.\n\n## Preliminary analysis\n\n\n::: {.cell}\n\n:::\n\n\n#### Q1 What is the letter in your data?\n\nThe letter in my data is 'y'.\n\n#### Q2 Plot a random sample of 12 images of your data with the correct orientation. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/letter-plot-1.png){width=672}\n:::\n:::\n\n\n\n#### Q3 Perform a principal component analysis (PCA) on your data. How much variation does the first 5 principal components explain in the data? \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nImportance of first k=5 (out of 784) components:\n                            PC1      PC2       PC3       PC4       PC5\nStandard deviation     667.3433 558.4448 520.02544 418.33520 408.85848\nProportion of Variance   0.1435   0.1005   0.08712   0.05638   0.05385\nCumulative Proportion    0.1435   0.2439   0.33105   0.38742   0.44128\n```\n:::\n:::\n\n\nWe can see that the first five principal components explain 44.128% of the variation in the data, and PC1, PC2, PC3, PC4 and PC5 explain 14.35%, 10.05%, 8.712%, 5.638% and 5.385% of the variation in the data respectively.\n\n#### Q4 Show what aspect of the data the first and second principal component loadings capture. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\n\n#### Q5 Using the rotated data from the PCA, perform an agglomerative hierarchical clustering with average linkage.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nhclust(d = dist(mydata_pca$x), method = \"average\")\n\nCluster method   : average \nDistance         : euclidean \nNumber of objects: 3448 \n```\n:::\n:::\n\n\n#### Q6 Cut the tree from question 5 to 4 clusters. Show how many observations you have per cluster.\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>How many observations in the 4 clusters.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> cave </th>\n   <th style=\"text-align:right;\"> Freq </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 3441 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n#### Q7 Show a sample of 10 (or the total number of images in a cluster if less than 10 observations in a cluster) images from each cluster like the plot below. What do you notice about the cluster groups? \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nWe could see that the tail of the letter 'y' seems to be straight and the upper part more like 'v' in cluster 1, while the tail of the letter 'y' is more curved and the upper part of the letter 'y' is more like 'u' in cluster 2. Then in cluster 3, the upper part of the letter 'y' is narrower in width than the lower part, and finally, in cluster 4 the upper part of the letter 'y' is like 'u' and the lower part of the letter 'y' is like 'v'. And the imbalance of clusters, majority of images are in one cluster, the other 3 clusters are smaller. \n\n\n## Report\n\n### Abstract\n\nHandwriting analysis has consistently captivated researchers, offering a window into the intricate details of human expression. Despite the prevalence of digital communication, handwriting remains pertinent, finding utility in diverse domains such as forensic document analysis, linguistics, and personalized marketing. This report explores the landscape of handwritten letter classification through the integration of Principal Component Analysis (PCA) and advanced machine learning techniques. By harnessing these methodologies, our objective is to decode the distinct variations present in how individuals write letters, thereby enhancing our understanding of the nuanced world of handwriting.\n\n### Choose pricipal components\n\nTo explore the way each person writes letters and to categorize the way they write them. I do a dimension reduction to the pixel data of a letter. And then, I produce a scree plot, and the elbow appears around the fourth to seventh PC (Principal component), therefore I choose 5 PCs (Principal components) to be used to analyze, and the 5 PCs (Principal components) explain 44.12% of the variation in the data.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nImportance of first k=5 (out of 784) components:\n                            PC1      PC2       PC3       PC4       PC5\nStandard deviation     667.3433 558.4448 520.02544 418.33520 408.85848\nProportion of Variance   0.1435   0.1005   0.08712   0.05638   0.05385\nCumulative Proportion    0.1435   0.2439   0.33105   0.38742   0.44128\n```\n:::\n:::\n\n\n### Classify data\n\nI choose the k-means method to divide the different ways that a person can write a particular letter into 3 clusters. This plot shows that the letter 'y' is more centered in cluster 1, and the letter 'y' is italic, the letter tends to lean to the right in cluster 2, and the letter 'y' is fatter and the upper part of the letter 'y' resembles a 'u' in cluster 3.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n### Classify new records\n\nFor classifying a set of new record of 5 observations, I use 3 supervised learning methods, and I set principal components as predictors.\n\n\n::: {.cell}\n\n:::\n\n\nI create three models by using the kNN method, the Support vector classifier method with Polynomial kernel and the Random forest method respectively to classify the new 5 observations. \n\n- kNN method \n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n- Support vector classifier method with Polynomial kernel\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n- Random forest method\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nWe can see that the classified results following the three models are the same and sensible, we could easily see that these are different 3 groups. Cluster 1 has a fatter letter, cluster 2 is more formal and centered, and cluster 3 leans a little to the right. \n\n### Compare models\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Accuracy of models</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> model </th>\n   <th style=\"text-align:right;\"> accuracy </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> kNN </td>\n   <td style=\"text-align:right;\"> 0.96 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Support vector classifier </td>\n   <td style=\"text-align:right;\"> 0.98 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Random forest </td>\n   <td style=\"text-align:right;\"> 0.97 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nWe could see that the accuracy of the Support vector classifier model is the best, which is 0.98.\n\n### Conclusion\n\nThe kNN model, the Support vector classifier model with the Polynomial kernel and the Random forest model are both good for classifying the new record of 5 observations, but following the accuracy of each model, I recommend the Support vector classifier model with the Polynomial kernel.\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}